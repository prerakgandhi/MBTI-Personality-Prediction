# -*- coding: utf-8 -*-
"""CS725-Models2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xOGSNdI9Unn4lxVefPa2cskSuJU5tdfM
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder
import pickle
import re
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
#nltk.download('wordnet')
from nltk.corpus import stopwords, wordnet
from nltk.stem import WordNetLemmatizer
from wordcloud import WordCloud

df = pd.read_csv("mbti_1.csv")

df.head()

df.info()

df.describe()

df['type'].value_counts()

df['posts']

df = df.dropna(axis=0)

def clear_text(data):
    data_length=[]
    lemmatizer=WordNetLemmatizer()
    cleaned_text=[]
    for sentence in data.posts:
        sentence=sentence.lower()
        
       # removing links from text data
        sentence=re.sub('https?://[^\s<>"]+|www\.[^\s<>"]+',' ',sentence)
    
       #  removing other symbols
        sentence=re.sub('[^0-9a-z]',' ',sentence)
    
        
        data_length.append(len(sentence.split()))
        cleaned_text.append(sentence)
    return cleaned_text,data_length

clear_df = df.copy()

clear_df['len_post'] = clear_df['posts'].apply(lambda x: len(x))

clear_df.len_post.mean()

clear_df.posts, _ = clear_text(clear_df)

clear_df['postlen'] = clear_df['posts'].apply(lambda x: len(x))

clear_df.postlen.mean()

clear_df.posts[50]

clear_df['postlen'].plot.hist(bins=50,color='green',alpha=0.5)
plt.title("Average length of each post")
plt.xlabel("Number of words")
plt.show()

test_size = 0.2
train_data,test_data = train_test_split(df,test_size=test_size,random_state=42,stratify=df.type)

train_data.posts,train_length = clear_text(train_data)
test_data.posts,test_length = clear_text(test_data)

class Lemmatizer(object):
    def __init__(self):
        self.lemmatizer = WordNetLemmatizer()
    def __call__(self, sentence):
        return [self.lemmatizer.lemmatize(word) for word in sentence.split() if len(word)>2]

vectorizer = TfidfVectorizer( max_features=5000,stop_words='english',tokenizer=Lemmatizer())
vectorizer.fit(train_data.posts)

train_post = vectorizer.transform(train_data.posts).toarray()
test_post = vectorizer.transform(test_data.posts).toarray()

train_post.shape, test_post.shape

target_encoder = LabelEncoder()
train_target = target_encoder.fit_transform(train_data.type)
test_target = target_encoder.fit_transform(test_data.type)

#Decision Trees

dtree = DecisionTreeClassifier(random_state=2)
dtree.fit(train_post, train_target)
dtpred = dtree.predict(test_post)

print(classification_report(test_target,dtpred))
print(confusion_matrix(test_target,dtpred))

print('train classification report \n ',classification_report(train_target,dtree.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))
print('test classification report \n',classification_report(test_target,dtree.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))



# Random Forest

rf = RandomForestClassifier(n_estimators = 100, random_state=2)
rf.fit(train_post, train_target)
rfpred = rf.predict(test_post)

print(classification_report(test_target,rfpred))
print(confusion_matrix(test_target,rfpred))

err_rate = []

for i in range(1400,2001,100):
    
    print(i)
    
    rfc = RandomForestClassifier(n_estimators = i, random_state=2)
    
    rfc.fit(train_post,train_target)
    
    prediction_i = rfc.predict(test_post)
    
    err_rate.append(np.mean(prediction_i != test_target))

plt.figure(figsize=(8,4))
plt.plot(range(1400,2001,100),err_rate,color='green', 
         marker='o',markerfacecolor='blue')
plt.title('Error Rate vs. No. of Estimators')
plt.xlabel('No. of Estimators')
plt.ylabel('Error_Rate')

rf = RandomForestClassifier(n_estimators = 1400, random_state=2)
rf.fit(train_post, train_target)
rfpred = rf.predict(test_post)

print('train classification report \n ',classification_report(train_target,rf.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))
print('test classification report \n',classification_report(test_target,rf.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))

print('train classification report \n ',classification_report(train_target,rf.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))
print('test classification report \n',classification_report(test_target,rf.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))



#KNN

# Initializing an empty list to get the error rate for every k 
err_rate = []

# Let's run the for loop for k from 1 to 30, we can use range() method
for i in range(10,51):
    
    # Initializing knn for k = i
    knn = KNeighborsClassifier(n_neighbors=i)
    
    # fitting knn 
    knn.fit(train_post,train_target)
    
    # predicting for k = i
    prediction_i = knn.predict(test_post)
    
    # error rate for k = i - appending to the list 'err_rate'
    # Avg of predictions and y_test if both not equal
    err_rate.append(np.mean(prediction_i != test_target))

plt.figure(figsize=(8,4))
plt.plot(range(10,51),err_rate,color='green', 
         marker='o',markerfacecolor='blue')
plt.title('Error Rate vs. K Value')
plt.xlabel('K_Value')
plt.ylabel('Error_Rate')

#neighbors = 32

knn = KNeighborsClassifier(n_neighbors=32)
knn.fit(train_post,train_target)
knnpred = knn.predict(test_post)

print(confusion_matrix(test_target,knnpred))
print(classification_report(test_target,knnpred))

print('train classification report \n ',classification_report(train_target,knn.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))
print('test classification report \n',classification_report(test_target,knn.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))







